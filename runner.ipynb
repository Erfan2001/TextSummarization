{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: six in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: pyrouge in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.3)\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Requirement already satisfied: dgl in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (2.30.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->dgl) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->dgl) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "! pip install rouge\n",
        "! pip install pyrouge\n",
        "! pip install  dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVRItSZqLAEe",
        "outputId": "16ead518-16c2-43a7-ff2a-dd46bbbf175d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-04 11:24:07,997 INFO    : Pytorch 2.0.0+cu117\n",
            "2023-06-04 11:24:07,997 INFO    : [INFO] Create Vocab, vocab path is HeterSumGraph\\cache\\CNNDM\\vocab\n",
            "2023-06-04 11:24:08,071 INFO    : [INFO] max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
            "2023-06-04 11:24:08,071 INFO    : [INFO] Finished constructing vocabulary of 50000 total words. Last word added: chaudhary\n",
            "2023-06-04 11:24:08,071 INFO    : [INFO] Word Embedding Dimension is 300\n",
            "2023-06-04 11:24:08,242 INFO    : Namespace(data_dir='datasets\\\\cnndm', cache_dir='HeterSumGraph\\\\cache\\\\CNNDM', embedding_path='embeddings\\\\glove.42B.300d.txt', model='HSG', restore_model='None', save_root='HeterSumGraph\\\\results\\\\log', log_root='HeterSumGraph\\\\results\\\\log', seed=666, gpu='0', cuda=True, vocab_size=50000, n_epochs=2, batch_size=32, n_iter=1, word_embedding=False, word_emb_dim=300, embed_train=False, feat_embed_size=50, n_layers=1, lstm_hidden_state=128, lstm_layers=2, bidirectional=True, n_feature_size=128, hidden_size=64, ffn_inner_hidden_size=512, n_head=8, recurrent_dropout_prob=0.1, atten_dropout_prob=0.1, ffn_dropout_prob=0.1, use_orthnormal_init=True, sent_max_len=100, doc_max_timesteps=50, lr=0.0005, lr_descent=True, grad_clip=True, max_grad_norm=1.0, m=3)\n",
            "2023-06-04 11:24:08,838 INFO    : [INFO] Use cuda\n",
            "2023-06-04 11:24:12,892 INFO    : [MODEL] HeterSumGraph \n",
            "Ali \"text\": [\"it was a moment of madness that nearly claimed this woman 's life .\", \"oblivious to the danger , she can be seen hopping and skipping on a spanish beach as ferocious waves whipped up by gale-force storms lash the shoreline .\", \"her two friends showed a little more sense and beat a hasty retreat as the tide swept in .\", \"but it was not until the last moment that the woman in the black swimsuit realised her danger and made a sprint for the concrete ramp which would lead her to safety .\", \"dancing with death : the woman ( right ) can be seen hanging back as her friends head for the concrete ramp off the beach to safety\", \"she was unable to outrun the water and was battered against the wall at sardinero beach , in santander , before being swept away by the waves .\", \"horrified witnesses can be seen watching her being carried along by the power of the water , unable to save her .\", \"one made a futile attempt to pull her to safety by offering his umbrella .\", \"it is understand that she survived her ordeal and emerged from the water with just bruises .\", \"the footage was shot on january 6 and uploaded to video sharing site liveleak.com .\", \"realising her mistake as the waves bear down on her , the woman can be seen running across the beach to try and make it before the tide\", \"but it is too late .\", \"the water sweeps her off her feet and she is carried along by the waves\", \"now flailing out of control , she is battered against the beach wall as her friends watch , unable to help\", \"as she is swept away , one bypasser made a desperate effort to reach her with an umbrella .\", \"luckily , she later emerged battered and bruised but alive\"], \"label\": [14, 15]}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"f:\\University\\Term8\\Final Project\\AmirReza_CleanCode\\HeterSumGraph\\train.py\", line 344, in <module>\n",
            "    main()\n",
            "  File \"f:\\University\\Term8\\Final Project\\AmirReza_CleanCode\\HeterSumGraph\\train.py\", line 311, in main\n",
            "    dataset = ExampleSet(DATA_FILE, vocab, hps.doc_max_timesteps, hps.sent_max_len, FILTER_WORD, train_w2s_path)\n",
            "  File \"f:\\University\\Term8\\Final Project\\AmirReza_CleanCode\\HeterSumGraph\\module\\dataloader.py\", line 161, in __init__\n",
            "    self.example_list = readJson(data_path)\n",
            "  File \"f:\\University\\Term8\\Final Project\\AmirReza_CleanCode\\HeterSumGraph\\module\\dataloader.py\", line 463, in readJson\n",
            "    data.append(json.loads(line))\n",
            "  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py\", line 346, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py\", line 340, in decode\n",
            "    raise JSONDecodeError(\"Extra data\", s, end)\n",
            "json.decoder.JSONDecodeError: Extra data: line 1 column 7 (char 6)\n"
          ]
        }
      ],
      "source": [
        "! python HeterSumGraph\\train.py \\\n",
        "                 --cuda --gpu 0 --data_dir datasets\\cnndm \\\n",
        "                     --cache_dir HeterSumGraph\\cache\\CNNDM \\\n",
        "                      --embedding_path embeddings\\glove.42B.300d.txt \\\n",
        "                       --model HSG \\\n",
        "                        --save_root HeterSumGraph\\results\\log \\\n",
        "                         --log_root HeterSumGraph\\results\\log \\\n",
        "                          --lr_descent \\\n",
        "                           --grad_clip \\\n",
        "                           --batch_size 32 -m 3 \\\n",
        "                           --n_epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1917494\n"
          ]
        }
      ],
      "source": [
        "with open('embeddings\\\\glove.42B.300d.txt','r',encoding='utf8') as f:\n",
        "    allList=f.readlines()\n",
        "print(len(allList))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Reduce Dataset\n",
        "\n",
        "# !copy HeterSumGraph\\cache\\CNNDM\\val.w2s.tfidf.jsonl Test\\Data\n",
        "count=100\n",
        "with open('Test\\\\Data\\\\val.w2s.tfidf.jsonl','r') as f:\n",
        "    allList=f.readlines()\n",
        "result=''\n",
        "for item in allList[:count]:\n",
        "    result+=item\n",
        "with open('HeterSumGraph\\\\cache\\\\CNNDM\\\\val.w2s.tfidf.jsonl','w') as f:\n",
        "    f.write(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "123\n"
          ]
        }
      ],
      "source": [
        "a='\"123\"'\n",
        "print(a[1:-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bkrq-fUtHdq_",
        "DtifeYChSohP"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
